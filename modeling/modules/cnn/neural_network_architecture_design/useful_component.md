

- [2004.08955] [ResNeSt: Split-Attention Networks](https://arxiv.org/abs/2004.08955)

- [CVPR2020] [Learning in the Frequency Domain](https://arxiv.org/abs/2002.12416)
  - [DCT](https://www.math.cuhk.edu.hk/~lmlui/dct.pdf)
  - [NIPS2018] [Faster Neural Networks Straight from JPEG](https://papers.nips.cc/paper/7649-faster-neural-networks-straight-from-jpeg.pdf) 
  - [IMVIP2017] [On using CNN with DCT based Image Data](https://www.scss.tcd.ie/Rozenn.Dahyot/pdf/IMVIP2017_MatejUlicny.pdf)

---

- [CVPR2019] [Attention Augmented Convolutional Networks](https://arxiv.org/abs/1904.09925)

- [1911.09737] [Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks](https://arxiv.org/abs/1911.09737)

- [1908.01259] [Attentive Normalization](https://arxiv.org/abs/1908.01259)

- [1906.02629] [When Does Label Smoothing Help?](https://arxiv.org/abs/1906.02629)

- [1905.11001] [On Mixup Training: Improved Calibration and Predictive Uncertainty for Deep Neural Networks](https://arxiv.org/abs/1905.11001)

- [1904.11486] [Making Convolutional Networks Shift-Invariant Again](https://arxiv.org/abs/1904.11486)

- [1904.05049] [Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution](https://arxiv.org/pdf/1904.05049)
  - Octave conv 
  - should be compared with [Multigrid Neural Architectures](https://arxiv.org/abs/1611.07661)

- [1904.04971] [Soft Conditional Computation](https://arxiv.org/abs/1904.04971)

---

- [1811.11718] [Partial Convolution based Padding](https://arxiv.org/abs/1811.11718)

- [1811.11168] [Deformable ConvNets v2: More Deformable, Better Results](https://arxiv.org/abs/1811.11168)

- [1810.12890] [DropBlock: A regularization method for convolutional networks](https://arxiv.org/abs/1810.12890)

- [1807.06521] [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521)

- [1805.12177] [Why do deep convolutional networks generalize so
poorly to small image transformations?](https://arxiv.org/abs/1805.12177)

- [1805.11604] [How Does Batch Normalization Help Optimization?](https://arxiv.org/abs/1805.11604)

- [CVPR2018] [Non-local neural networks](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf)

---

- [CVPR2017] [Multigrid Neural Architectures](https://arxiv.org/abs/1611.07661)

- [1709.01507] [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) # SE

- [1708.02002] [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

- [1703.06211] [Deformable Convolutional Networks](https://arxiv.org/pdf/1703.06211.pdf) | [slides](http://presentations.cocodataset.org/COCO17-Detect-MSRA.pdf) | [tutorial](https://towardsdatascience.com/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44)

- [1703.02719] [Large Kernel Matters ——
Improve Semantic Segmentation by Global Convolutional Network](https://arxiv.org/abs/1703.02719) #GCN

- [1702.03275] [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1702.03275)

---

- [1611.07661] [Multigrid Neural Architectures](https://arxiv.org/abs/1611.07661)

- [1603.05201] [Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units](https://arxiv.org/abs/1603.05201) # CReLU

---

- [1502.03167] [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)

- [1412.6806] [Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)
